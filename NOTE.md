## 提示工程 & 执行流程

https://www.bilibili.com/video/BV11Pq8BQEdM/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=f1c2bd827223f189550f61d34208e90e

1. 相同模型，预设用不同的提示，准确率可以差很多；
2. 提示工程无法 1 次开发完成，需要长期迭代；
3. 提示正从 手写 逐渐转为 生成；

步骤：

1. 整理流程设计：Ai Pipeline ：把 AI 视为「信息处理工厂」，Pipeline 是流水线，将复杂的任务拆解为 Input -> Process -> Output 。方便重复、拓展。

2. 获取正确、实时资料：RAG：连接外部知识库。

3. 基于资料整理：Chain Of Thought(CoT)：让 AI 展示推理步骤，将黑盒思维过程透明化，从而降低逻辑错误。

- CoT 会强制模型显式的使用预期的逻辑思路生成答案，而不是偷偷的快思考；
- 将思考过程展示出来是当前唯 1 确保约束模型行为的有效方式；

优化思路：

1. Zero-Shot or Few-Shot

2. 特异性 & 分隔符 & 角色扮演

3. 任务分解：把 大任务 拆分成模型能稳定完成的小步骤

4. 自我修正

5. ReAct 框架：推理和行动的循环

6. Meta-Prompting & Prompt Chaining

## 高价值场景：图像与代码生成的专项策略

图像提示词公式：

- 主体：定义画面中的核心角色和动作
- 风格：决定画面的整体气质与流派
- 细节：补充光影、事件与环境氛围
- 格式：设定画面的物理规格（尺寸）与用途（如海报，壁纸）
- 负向约束：明确告知 AI 「不要出现什么」

代码生成策略：

- 明确需求
  - 指定语言与环境
  - 定义输入输出格式
  - 强调性能与安全边际
- 逻辑拆分
  - 将大任务拆分成独立的模块和子步骤
- 人类编写注释（伪代码），再由模型填充实现
- 自查与优化

## 安全风险与自动化未来

注入攻击：隐藏的「攻击指令」：只要需要模型读取外部资源，就有可能把隐藏起来的指令 1 并执行；

- 防御：最小权限 & 人工确认；
  - 功能原子化：只授予完成当前任务所需要的最小权限，AI 写文案仅需素材库访问权限，而非全系统权限；
  - 读写分离：查询资料任务仅需「只读」权限，严禁赋予写入或删除能力，限制潜在损失范围；
  - 对于高风险操作（转账、权限修改、群发、删库）强制介入人工审核；
    （模型就是会被诱导、犯错）

提示工程的迭代流程：运行、评估 & 修正

从「手工提示工程」走向「自动化提示编程」：DSPy 框架与人类专家的效能对比
